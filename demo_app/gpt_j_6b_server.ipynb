{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azureuser/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from transformers import GPTJForCausalLM, GPT2Tokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Will need at least 13-14GB of Vram for CUDA\n",
    "if torch.cuda.is_available():\n",
    "    model =  GPTJForCausalLM.from_pretrained(\"EleutherAI/gpt-j-6B\",cache_dir=\"/datadrive/cache_dir/\", torch_dtype=torch.float16).cuda()\n",
    "else:\n",
    "    print(\"GPU not available, check driver and cuda installation and reboot if neccessary\")\n",
    "    #model =  GPTJForCausalLM.from_pretrained(\"EleutherAI/gpt-j-6B\", torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_description = \"\"\"\n",
    "Name: Max  Occupation: Consultant Salary: 500\n",
    "Name: Sam  Occupation: Consultant Salary: 600\n",
    "Name: James Occupation: Consultant Salary: 700\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name: Max  Occupation: Consultant Salary: 500\n",
      "Name: Sam  Occupation: Consultant Salary: 600\n",
      "Name: James Occupation: Consultant Salary: 700\n",
      "\n",
      "I want to create a query which takes Max's salary and the total number of Consultants in the list and then return the names of all the consultants who earn more than Max.\n",
      "I have tried with following query, but it returns only one result.\n",
      "WITH cte AS(  \n",
      "  SELECT Name, Occupation, Salary, ROW_NUMBER() OVER (PARTITION BY Name) rn \n",
      "  FROM Employee\n",
      ")\n",
      "SELECT Name, Occupation, Salary\n",
      "FROM cte\n",
      "WHERE rn = 1\n",
      "\n",
      "A:\n",
      "\n",
      "You can use subquery:\n",
      "SELECT *\n",
      "FROM ( \n",
      "  SELECT *\n",
      "  FROM Employee\n",
      ") t\n",
      "WHERE Salary > ( SELECT MAX( Salary ) FROM Employee )\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_text = environment_description\n",
    "input_ids = tokenizer.encode(str(input_text), return_tensors='pt').cuda()\n",
    "\n",
    "output = model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True,\n",
    "    top_p=0.99,\n",
    "    top_k=10,\n",
    "    temperature=0.9,\n",
    "    max_new_tokens=200,\n",
    "    #penalty_alpha=0.6\n",
    "\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5002 (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [11/Nov/2022 00:51:19] \"\u001b[33mGET /generate/Question:%20Fetch%20the%20companies%20that%20have%20less%20than%20five%20people%20in%20it.%0A%20%20%20%20%20%20%20%20%20%20%20%20Answer:%20SELECT%20COMPANY,%20COUNT(EMPLOYEE_ID)%20FROM%20Employee%20GROUP%20BY%20COMPANY%20HAVING%20COUNT(EMPLOYEE_ID)%20%3C%205;%0A%20%20%20%20%20%20%20%20%20%20%20%20 HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request\n",
    "from flask_restful import Resource, Api\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "api = Api(app)\n",
    "\n",
    "class generate_text(Resource):\n",
    "    def get(self, text, tokens):\n",
    "\n",
    "        environment_description = text\n",
    "\n",
    "        input_text = environment_description\n",
    "        input_ids = tokenizer.encode(str(input_text), return_tensors='pt').cuda()\n",
    "\n",
    "        output = model.generate(\n",
    "            input_ids,\n",
    "            do_sample=True,\n",
    "            top_p=0.99,\n",
    "            top_k=10,\n",
    "            temperature=0.9,\n",
    "            max_new_tokens=int(tokens)*10,\n",
    "            penalty_alpha=0.6\n",
    "            )\n",
    "\n",
    "        out = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        \n",
    "        \n",
    "        result = {\"result\":out}\n",
    "        return result   \n",
    "        \n",
    "api.add_resource(generate_text, '/generate/<text>/<tokens>') # Route_1\n",
    "\n",
    "app.run(port='5002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5002 (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [11/Nov/2022 00:59:45] \"GET /generate HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Nov/2022 01:00:05] \"GET /generate HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Nov/2022 01:00:31] \"GET /generate HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/generate', methods=['GET']) \n",
    "def generate():\n",
    "    data = request.json\n",
    "    \n",
    "    return jsonify(data)\n",
    "\n",
    "app.run(port='5002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5002 (Press CTRL+C to quit)\n",
      "[2022-11-11 01:16:13,906] ERROR in app: Exception on /generate [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/azureuser/.local/lib/python3.8/site-packages/flask/app.py\", line 2077, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/home/azureuser/.local/lib/python3.8/site-packages/flask/app.py\", line 1525, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/home/azureuser/.local/lib/python3.8/site-packages/flask/app.py\", line 1523, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/home/azureuser/.local/lib/python3.8/site-packages/flask/app.py\", line 1509, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)\n",
      "  File \"/tmp/ipykernel_48685/1037202936.py\", line 8, in generate\n",
      "    data = json.loads(request.json)\n",
      "  File \"/home/azureuser/anaconda3/envs/ldm/lib/python3.8/json/__init__.py\", line 357, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/home/azureuser/anaconda3/envs/ldm/lib/python3.8/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/home/azureuser/anaconda3/envs/ldm/lib/python3.8/json/decoder.py\", line 353, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "json.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
      "127.0.0.1 - - [11/Nov/2022 01:16:13] \"\u001b[35m\u001b[1mGET /generate HTTP/1.1\u001b[0m\" 500 -\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'body': 'This is a testhhh Answer:', 'token': '10'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [11/Nov/2022 01:18:51] \"GET /generate HTTP/1.1\" 200 -\n",
      "[2022-11-11 01:19:35,284] ERROR in app: Exception on /generate [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/azureuser/.local/lib/python3.8/site-packages/flask/app.py\", line 2077, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/home/azureuser/.local/lib/python3.8/site-packages/flask/app.py\", line 1525, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/home/azureuser/.local/lib/python3.8/site-packages/flask/app.py\", line 1523, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/home/azureuser/.local/lib/python3.8/site-packages/flask/app.py\", line 1509, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)\n",
      "  File \"/tmp/ipykernel_48685/1037202936.py\", line 8, in generate\n",
      "    data = json.loads(request.json)\n",
      "  File \"/home/azureuser/anaconda3/envs/ldm/lib/python3.8/json/__init__.py\", line 357, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/home/azureuser/anaconda3/envs/ldm/lib/python3.8/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/home/azureuser/anaconda3/envs/ldm/lib/python3.8/json/decoder.py\", line 353, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "json.decoder.JSONDecodeError: Invalid control character at: line 1 column 79 (char 78)\n",
      "127.0.0.1 - - [11/Nov/2022 01:19:35] \"\u001b[35m\u001b[1mGET /generate HTTP/1.1\u001b[0m\" 500 -\n",
      "[2022-11-11 01:21:09,343] ERROR in app: Exception on /generate [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/azureuser/.local/lib/python3.8/site-packages/flask/app.py\", line 2077, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/home/azureuser/.local/lib/python3.8/site-packages/flask/app.py\", line 1525, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/home/azureuser/.local/lib/python3.8/site-packages/flask/app.py\", line 1523, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/home/azureuser/.local/lib/python3.8/site-packages/flask/app.py\", line 1509, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)\n",
      "  File \"/tmp/ipykernel_48685/1037202936.py\", line 8, in generate\n",
      "    data = json.loads(request.json)\n",
      "  File \"/home/azureuser/anaconda3/envs/ldm/lib/python3.8/json/__init__.py\", line 357, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/home/azureuser/anaconda3/envs/ldm/lib/python3.8/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/home/azureuser/anaconda3/envs/ldm/lib/python3.8/json/decoder.py\", line 353, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "json.decoder.JSONDecodeError: Invalid control character at: line 1 column 79 (char 78)\n",
      "127.0.0.1 - - [11/Nov/2022 01:21:09] \"\u001b[35m\u001b[1mGET /generate HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import json\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/generate', methods=['GET']) \n",
    "def generate():\n",
    "\n",
    "\n",
    "    data = json.loads(request.json, strict=False)\n",
    "    print(data)\n",
    "\n",
    "    environment_description = data[\"body\"]\n",
    "\n",
    "    input_text = environment_description\n",
    "    input_ids = tokenizer.encode(str(input_text), return_tensors='pt').cuda()\n",
    "\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        do_sample=True,\n",
    "        top_p=0.99,\n",
    "        top_k=10,\n",
    "        temperature=0.9,\n",
    "        max_new_tokens=int(data['token'])*10,\n",
    "        penalty_alpha=0.6\n",
    "        )\n",
    "\n",
    "    out = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    \n",
    "    \n",
    "    result = {\"result\":out}\n",
    "    \n",
    "    return jsonify(result)\n",
    "\n",
    "app.run(port='5002')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('ldm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "02d2c4a433672b1324c93c9860b07975f9008655601f1a75418acae9093eae80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
